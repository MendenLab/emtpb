{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c9035-d82e-4941-ba3a-6c7beb078f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from sys import exit\n",
    "#os.chdir(Path(os.path.realpath('__file__')).parents[1])\n",
    "#sys.path.append(Path(os.path.realpath('__file__')).parents[1])\n",
    "current_dir = os.path.abspath(os.path.dirname('__file__'))\n",
    "current_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "os.chdir(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "print(current_dir)\n",
    "\n",
    "os.chdir('/lustre/groups/cbm01/code/alexander.ohnmacht/emtpb')\n",
    "sys.path.append('/lustre/groups/cbm01/code/alexander.ohnmacht/emtpb')\n",
    "#os.chdir('/vol/emtpb/emtpb')\n",
    "#sys.path.append('/vol/emtpb/emtpb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470e696-7500-465f-82b2-ec67e4617b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import math\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "\n",
    "from econml import sklearn_extensions\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "#run = \"run6\"\n",
    "score = [\"\",\"_gsva\",\"_tan_088\",\"_secrier_065\"]\n",
    "model_type = [\"eln\",\"grf\"]\n",
    "response_type = [\"\",\"_auc\"]\n",
    "cancer_type = range(28)\n",
    "drug = range(700)\n",
    "\n",
    "# create all possible combinations\n",
    "combinations = list(itertools.product(score, model_type, response_type, cancer_type, drug))\n",
    "\n",
    "# create a DataFrame for each combination\n",
    "dfs = []\n",
    "for comb in combinations:\n",
    "    df = pd.DataFrame(list(comb)).T\n",
    "    df.columns = [\"score\", \"model_type\", \"response_type\", \"cancer_type\",\"drug\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# initialize a counter\n",
    "counter = 0\n",
    "# iterate over the rows of the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    # increment the counter by 1 every 28th row\n",
    "    if i % len(range(700*28)) == 0:\n",
    "        counter += 1\n",
    "    # add the counter value to a new column\n",
    "    df.loc[i, 'run'] = str(counter+6)\n",
    "\n",
    "# save DataFrame df\n",
    "# df.to_csv(\"metadata/paper/benchmark_paper_exp3.csv\", index=True)\n",
    "df = pd.read_csv(\"metadata/paper/benchmark_paper_exp4.csv\", index_col=0)\n",
    "\n",
    "verbose = False # verbose=T does not work for CE\n",
    "example = True # \"1159-GDSC2\" # False\n",
    "cv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce60310-4cdc-4bac-8ada-f0067275e7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use one parameter dict\n",
    "if len(sys.argv)!=2:\n",
    "    argument = ['-',1]\n",
    "else:\n",
    "    print('cmd entry:', sys.argv)\n",
    "    argument = sys.argv\n",
    "which_run = int(argument[1]) - 1\n",
    "print(\"emtpb: Parallel run \"+str(which_run))\n",
    "### costum\n",
    "#which_run = 24\n",
    "###\n",
    "\n",
    "# assign values for run\n",
    "print(\"emtpb: Updated manual parallel run \"+str(which_run))\n",
    "params = df.iloc[which_run]\n",
    "\n",
    "print(params)\n",
    "run = 'run'+str(params['run'])\n",
    "score = params['score']\n",
    "model_type = params['model_type']\n",
    "response_type = params['response_type']\n",
    "cancer_type = params['cancer_type']\n",
    "index_drug = params['drug'] # was not there\n",
    "\n",
    "#define cancer types based on marisa\n",
    "EMTscores = pd.read_csv(\"metadata/EMTscores.csv\")\n",
    "cancertypes = np.concatenate((['PANCAN'], EMTscores['TCGA Desc'].unique()))\n",
    "#select to be screened\n",
    "EMTscores = pd.read_csv(\"metadata/EMTscores\"+str(score)+\".csv\")\n",
    "cancertypes_here = np.concatenate((['PANCAN'], EMTscores['TCGA Desc'].unique()))\n",
    "\n",
    "#end run if it does not exist\n",
    "if cancertypes[cancer_type] not in cancertypes_here:\n",
    "    exit(0)\n",
    "\n",
    "preds_dir = \"metadata/\"+run+\"/predictions/\"+cancertypes[cancer_type]+\"/\"\n",
    "model_dir = \"metadata/\"+run+\"/models/\"+cancertypes[cancer_type]+\"/\"\n",
    "#preds_dir = \"metadata/\"+run+\"/predictions/\"+cancertypes[cancer_type]+\"/\"\n",
    "#model_dir = \"metadata/\"+run+\"/models/\"+cancertypes[cancer_type]+\"/\"\n",
    "os.makedirs(preds_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "mut = pd.read_csv(\"metadata/matrix_mut_\"+cancertypes[cancer_type]+\".csv\")\n",
    "#mut = pd.read_csv(\"metadata/matrix_mut_\"+cancertypes[cancer_type]+\".csv\")\n",
    "resp_full = pd.read_csv(\"metadata/matrix_resp\"+response_type+\".csv\")\n",
    "cols = resp_full.columns[resp_full.columns.str.contains('GDSC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c6c61-31b3-460e-b137-c535039cfd6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def t_test(x, vadj=7.25): # 7.25 for 5x5 cv\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = len(x)\n",
    "    stat = np.mean(x) / np.sqrt(np.var(x)/n*vadj)\n",
    "    return 2 * stats.t.sf(np.abs(stat), n-1)\n",
    "\n",
    "\n",
    "def run_model_cv(X, y, outer_seed, inner_seed, model_dir, preds_dir, names, which_index, outer_folds = 5, inner_folds = 5, repeats = 5, baseline = False, save_models = False, model_type = \"eln\", check_for_trained = True, min_samples = 25, save = True):\n",
    "    \n",
    "    # predictions save path and check if its exists already\n",
    "    preds_filename = os.path.join(preds_dir, f\"predictions_{model_type}_{which_index}_{baseline}.csv\")\n",
    "    if check_for_trained:\n",
    "        if Path(preds_filename).exists():\n",
    "            print(\"emtpb: iteration \"+str(index)+\" already exists... skipping...\")\n",
    "            return\n",
    "    \n",
    "    # remove interesting variable for baseline\n",
    "    if baseline:\n",
    "        X = np.delete(X, 0, axis=1)\n",
    "    \n",
    "    # initialize list of all preds\n",
    "    all_all_predictions = []\n",
    "    all_all_truth = []\n",
    "    all_all_folds = []\n",
    "    all_all_effects = []\n",
    "   \n",
    "    # Initialize names\n",
    "    names = pd.DataFrame(names)\n",
    "    names = pd.concat([names]*repeats, ignore_index = True)\n",
    "    \n",
    "    # check size of X,y and save placeholder\n",
    "    if mat.shape[0] < min_samples: # minimum 25 samples needed (5 test samples in outer cv and 4 in inner)\n",
    "        print(\"Amount of columns is only \"+str(mat.shape[0])+\"... skipping\")\n",
    "        names.to_csv(preds_filename, index=False)\n",
    "        return\n",
    "    \n",
    "    # initialize the outer cross-validation\n",
    "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=outer_seed)\n",
    "\n",
    "    # initialize the inner cross-validation\n",
    "    inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=inner_seed)\n",
    "\n",
    "    # repeat the outer cross-validation 5 times\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        # initialize the list to store the predictions\n",
    "        all_predictions = []\n",
    "        all_truth = []\n",
    "        all_folds = []\n",
    "        all_effects = []\n",
    "\n",
    "        # set the seed for the outer cross-validation\n",
    "        outer_cv.random_state = outer_seed + repeat\n",
    "\n",
    "        # loop through the splits of the outer cross-validation\n",
    "        for i, (train_index, test_index) in enumerate(outer_cv.split(X)):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # initialize the model\n",
    "            \n",
    "            # elastic net\n",
    "            if model_type == \"eln\":\n",
    "                #model = ElasticNetCV(l1_ratio=[0.01, .1, .5, .9, .95, 1],\n",
    "                #                     cv=inner_cv,\n",
    "                #                     random_state=inner_seed,\n",
    "                #                     tol=0.01)\n",
    "                model = sklearn_extensions.linear_model.WeightedLassoCV(random_state = inner_seed)\n",
    "                \n",
    "            # random forest\n",
    "            if model_type == \"rf\":\n",
    "                model = RandomForestRegressor(random_state=inner_seed)\n",
    "                \n",
    "                \n",
    "            # neural network\n",
    "            if model_type == \"mlp\":\n",
    "                model = MLPRegressor(max_iter=1000,\n",
    "                                     random_state=inner_seed)\n",
    "                # Define the hyperparameters to search over\n",
    "                \n",
    "                hidden_layer_sizes = [10, 50, 100, 150, 200]\n",
    "                n_layers = [2, 3 , 4]\n",
    "                layer_permutations = list(itertools.chain(*[itertools.permutations(hidden_layer_sizes, n) for n in n_layers]))\n",
    "                \n",
    "                param_grid = {\n",
    "                    'hidden_layer_sizes': layer_permutations\n",
    "                    #'activation': ['relu'] # 'identity', 'logistic', 'tanh', \n",
    "                    #'learning_rate_init': [0.001]\n",
    "                }\n",
    "                grid_search = RandomizedSearchCV(model, param_grid, cv=inner_folds, n_iter = 10, random_state = i+repeat*35)\n",
    "                grid_search.fit(X, y)\n",
    "                model = grid_search.best_estimator_\n",
    "                \n",
    "                # Get the best hyperparameters\n",
    "                print(grid_search.best_params_)\n",
    "                \n",
    "                \n",
    "            ############################    \n",
    "            if model_type in [\"eln\",\"rf\",\"mlp\"]:\n",
    "                \n",
    "                # fit the model on the training data\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # make predictions on the test set\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # save the predictions\n",
    "                all_predictions.append(y_pred)\n",
    "                all_truth.append(y_test)\n",
    "                all_folds.append([i]*len(y_test))\n",
    "                all_effects.append([0]*len(y_test))\n",
    "                \n",
    "            # causal modelling\n",
    "            if model_type in [\"grf\"]:\n",
    "\n",
    "                #basemodel = ElasticNetCV(l1_ratio=[0.01, .1, .5, .9, .95, 1],\n",
    "                #                         cv=inner_cv,\n",
    "                #                         random_state=inner_seed,\n",
    "                #                         tol=0.01)\n",
    "                \n",
    "                # fit the model on the training data\n",
    "                np.random.seed(123)\n",
    "                model = CausalForestDML(discrete_treatment=False, random_state=123) #, model_y=basemodel, model_t=basemodel)\n",
    "\n",
    "                if cv:\n",
    "                    #tmp = np.array(y) # np.random.permutation(\n",
    "                    X_red = np.delete(X_train,(0), axis=1) #\n",
    "                    X_red_test = np.delete(X_test,(0), axis=1) #\n",
    "\n",
    "                    # fit model\n",
    "                    model.fit(Y = y_train, T = X_train[:,0], X = X_red) #model.fit(tmp, mat[:,0], X=matt)\n",
    "                    summary = model.effect_inference(X_red_test) #, model.const_marginal_ate_interval(np.delete(mat,(0), axis=1))\n",
    "                    #print(summary)\n",
    "                    #print(summary.pvalue())\n",
    "                    \n",
    "                    # make predictions on the test set\n",
    "                    #y_pred = model.predict(X_test)\n",
    "                    #pdb.set_trace()\n",
    "                    #global T_TRAIN\n",
    "                    #T_TRAIN = X_train[:,0]\n",
    "                    #global T_TEST\n",
    "                    #T_TEST = X_test[:,0]\n",
    "                    #global X_TRAIN\n",
    "                    #X_TRAIN = X_red\n",
    "                    #global X_TEST\n",
    "                    #X_TEST = X_red_test\n",
    "                    #global Y_TRAIN\n",
    "                    #Y_TRAIN = y_train\n",
    "                    #global Y_TEST\n",
    "                    #Y_TEST = y_test\n",
    "                    #global MODEL\n",
    "                    #MODEL = model\n",
    "                    #return \n",
    "                    \n",
    "                    #MODEL.models_y[0][-1].predict(X_TEST) + MODEL.effect(X_TEST) * (MODEL.models_t[0][-1].predict(X_TEST)+T_TEST)\n",
    "                    #y_pred = model.effect(X_red_test)\n",
    "                    y_pred = model.models_y[0][-1].predict(X_red_test) + model.effect(X_red_test) * (X_test[:,0] - model.models_t[0][-1].predict(X_red_test))\n",
    "\n",
    "                    # save the predictions\n",
    "                    all_predictions.append(y_pred)\n",
    "                    all_truth.append(y_test)\n",
    "                    all_folds.append([i]*len(y_test))\n",
    "                    all_effects.append([np.array2string(np.array([summary.pvalue(),model.effect(X_red_test),model.effect_interval(X_red_test)], dtype=object))]*len(y_test)) # transformback with: transformed_array = np.fromstring(my_array.replace('\\n', '').replace(' ', ',').replace(',,',',').replace('(','').replace(')','')[1:-1], sep=',')\n",
    "                    #all_folds.append([i]*len(y_test))\n",
    "                    \n",
    "                    pass\n",
    "                    \n",
    "                else:\n",
    "                    # ignore train and test because we don't need it here\n",
    "                    #tmp = np.array(y) # np.random.permutation(\n",
    "                    X_red = np.delete(X,(0), axis=1) #\n",
    "\n",
    "                    # fit model\n",
    "                    model.fit(y, X[:,0], X=X_red) #model.fit(tmp, mat[:,0], X=matt)\n",
    "                    summary = model.effect_inference(X_red) #, model.const_marginal_ate_interval(np.delete(mat,(0), axis=1))\n",
    "                    #print(summary)\n",
    "                    #print(summary.pvalue())\n",
    "                    \n",
    "                    # make predictions on the test set\n",
    "                    #y_pred = model.predict(X_test)\n",
    "                    y_pred = model.effect(X_red)\n",
    "\n",
    "                    # save the predictions\n",
    "                    all_predictions.append(y_pred)\n",
    "                    all_truth.append(y)\n",
    "                    all_folds.append([i]*len(y_test))\n",
    "                    all_effects.append([np.array2string(np.array([summary.pvalue(),model.effect(X_red),model.effect_interval(X_red)], dtype=object))]*len(y)) # transformback with: transformed_array = np.fromstring(my_array.replace('\\n', '').replace(' ', ',').replace(',,',',').replace('(','').replace(')','')[1:-1], sep=',')\n",
    "                    #all_folds.append([i]*len(y_test))\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                if cv:\n",
    "                    pass\n",
    "                else:\n",
    "                    break # exit the loop after causal estimation without cv\n",
    "                \n",
    "            # save the predictions\n",
    "            #all_predictions.append(y_pred)\n",
    "            #all_truth.append(y_test)\n",
    "            #all_folds.append([i]*len(y_test))\n",
    "\n",
    "            # save the model\n",
    "            model_filename = os.path.join(model_dir, f\"model_{model_type}_{which_index}_{baseline}_{repeat}_{i}.joblib\")\n",
    "            if save_models:\n",
    "                joblib.dump(model, model_filename)\n",
    "\n",
    "        # concatenate all the predictions from cv\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_truth = np.concatenate(all_truth)\n",
    "        all_folds = np.concatenate(all_folds)\n",
    "        all_effects = np.concatenate(all_effects)\n",
    "        \n",
    "        # save the cv results and append to resampling\n",
    "        all_all_predictions.append(all_predictions)\n",
    "        all_all_truth.append(all_truth)\n",
    "        all_all_folds.append(all_folds)\n",
    "        all_all_effects.append(all_effects)\n",
    "    \n",
    "    # concatenate all the predictions\n",
    "    all_all_predictions = np.concatenate(all_all_predictions)\n",
    "    all_all_truth = np.concatenate(all_all_truth)\n",
    "    all_all_folds = np.concatenate(all_all_folds)\n",
    "    all_all_effects = np.concatenate(all_all_effects)\n",
    "    \n",
    "    names[\"preds\"] = all_all_predictions\n",
    "    names[\"truth\"] = all_all_truth#np.concatenate([y]*repeats)\n",
    "    names[\"repeat\"] = np.concatenate([[i]*len(y) for i in range(repeats)])\n",
    "    names[\"folds\"] = all_all_folds\n",
    "    names[\"repeatfold\"] = names[\"repeat\"].astype(str) + names[\"folds\"].astype(str)\n",
    "    names[\"effects\"] = all_all_effects\n",
    "    \n",
    "    # save predictions \n",
    "    if save:\n",
    "        names.to_csv(preds_filename, index=False)\n",
    "        \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543c0d8-3677-427a-890a-ff452011bd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# benchmark\n",
    "for index in range(len(cols)):\n",
    "    \n",
    "    ### costum\n",
    "    #index = 0\n",
    "    ###\n",
    "    if not not example:\n",
    "        index = index_drug #np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "    \n",
    "    print(\"emtpb: modelling iteration \"+str(index)+\"...\")\n",
    "    #index = np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "\n",
    "    # get one response column\n",
    "    resp = resp_full.copy()\n",
    "    resp = resp[[\"COSMIC ID\",\"TCGA Desc\",cols[index]]]\n",
    "    mat = pd.merge(EMTscores, resp, how='outer')\n",
    "    if cancertypes[0] != \"PANCAN\":\n",
    "        mat = mat[mat['TCGA Desc'] == cancertypes[cancer_type]]\n",
    "    mat = pd.merge(mat, mut, how='outer')\n",
    "    mat = pd.get_dummies(mat)\n",
    "    mat_df = mat\n",
    "    print(\"empb: shape before removing nan is \"+str(mat.shape))\n",
    "    mat.dropna(inplace=True)\n",
    "    print(\"empb: shape after removing nan is \"+str(mat.shape))\n",
    "    if mat.shape[0] == 0:\n",
    "        df = pd.DataFrame([[0]*mat.shape[1]],columns=mat.columns)\n",
    "        mat = mat.append(df, ignore_index=True)\n",
    "    names = mat['COSMIC ID']\n",
    "    mat.drop(columns=['COSMIC ID'], inplace=True)\n",
    "    response = mat.iloc[:,1] # mat.iloc[:,1] (drug response), # mat.iloc[:,0] (emt score)\n",
    "    mat = mat.drop(mat.columns[1], axis=1)\n",
    "    scale = StandardScaler()\n",
    "    mat = scale.fit_transform(mat)\n",
    "\n",
    "    for baseline in [True,False]: # [True, False]\n",
    "        if model_type == \"grf\" and baseline == True:\n",
    "            continue # skip baseline calcs for causal modelling\n",
    "        df = run_model_cv(\n",
    "            X = mat,\n",
    "            y = np.array(response),\n",
    "            outer_seed = 53+53, \n",
    "            inner_seed = 53,\n",
    "            model_dir = model_dir,\n",
    "            preds_dir = preds_dir,\n",
    "            names = names,\n",
    "            which_index = index,\n",
    "            repeats = 5, #(1 if model_type == 'grf' else 5), # <------- SET TO 5\n",
    "            baseline = baseline,\n",
    "            model_type = model_type,\n",
    "            save_models = False,\n",
    "            check_for_trained = True,\n",
    "            outer_folds = 5,\n",
    "            save = True\n",
    "        )\n",
    "        \n",
    "        if df is not None:\n",
    "            test = df #pd.read_csv(preds_dir+\"predictions_\"+str(model_type)+\"_\"+str(index)+\"_False.csv\") # df if save=False\n",
    "            per = np.array(test.groupby(\"repeatfold\")[['preds','truth']].corr().iloc[1::2,0])\n",
    "            per[np.isnan(per)] = 0\n",
    "            print(np.mean(per)) #\n",
    "\n",
    "    if verbose:\n",
    "        test = pd.read_csv(preds_dir+\"predictions_\"+str(model_type)+\"_\"+str(index)+\"_False.csv\") # df if save=False\n",
    "        perfalse = np.array(test.groupby(\"repeatfold\")[['preds','truth']].corr().iloc[1::2,0])\n",
    "        perfalse[np.isnan(perfalse)] = 0\n",
    "        print(perfalse)\n",
    "        print(np.mean(perfalse)) # \n",
    "        test = pd.read_csv(preds_dir+\"predictions_\"+str(model_type)+\"_\"+str(index)+\"_True.csv\") # df if save=False\n",
    "        pertrue = np.array(test.groupby(\"repeatfold\")[['preds','truth']].corr().iloc[1::2,0])\n",
    "        pertrue[np.isnan(pertrue)] = 0\n",
    "        print(pertrue)\n",
    "        print(np.mean(pertrue)) #\n",
    "        print(\"t-test p=\"+str(t_test(perfalse-pertrue)))\n",
    "        \n",
    "    if not not example:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43b280-6f49-459c-9c42-75ecb333ea62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"emt_pb: done modelling \"+cancertypes[cancer_type]+\" for run \"+str(which_run)+\" and drug index \"+str(index_drug)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b60d57-19f3-4373-9b0a-c849a9fa0023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check feature importances\n",
    "#m = joblib.load(\"metadata/run1/models/SKCM/model_513_False_0_0.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dae857-7385-4511-9f31-e01b91ef0168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18fb7a0-d547-4726-bb92-46f7f496ccc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
