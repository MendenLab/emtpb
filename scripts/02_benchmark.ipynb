{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c9035-d82e-4941-ba3a-6c7beb078f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import math\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "os.chdir(Path(__file__).parents[1])\n",
    "sys.path.append(Path(__file__).parents[1])\n",
    "\n",
    "run = \"run2\"\n",
    "verbose = False\n",
    "example = False # \"1159-GDSC2\" # False\n",
    "model_type = \"eln\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce60310-4cdc-4bac-8ada-f0067275e7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use one parameter dict\n",
    "if len(sys.argv)!=2:\n",
    "    argument = ['-',1]\n",
    "else:\n",
    "    print('cmd entry:', sys.argv)\n",
    "    argument = sys.argv\n",
    "which_run = int(argument[1]) - 1\n",
    "print(\"emtpb: Parallel run \"+str(which_run))\n",
    "\n",
    "### costum\n",
    "#which_run = 0\n",
    "###\n",
    "\n",
    "print(\"emtpb: Updated manual parallel run \"+str(which_run))\n",
    "\n",
    "EMTscores = pd.read_csv(\"metadata/EMTscores.csv\")\n",
    "cancertypes = np.concatenate((['PANCAN'], EMTscores['TCGA Desc'].unique()))\n",
    "preds_dir = \"metadata/\"+run+\"/predictions/\"+cancertypes[which_run]+\"/\"\n",
    "model_dir = \"metadata/\"+run+\"/models/\"+cancertypes[which_run]+\"/\"\n",
    "os.makedirs(preds_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "mut = pd.read_csv(\"metadata/matrix_mut_\"+cancertypes[which_run]+\".csv\")\n",
    "resp_full = pd.read_csv(\"metadata/matrix_resp.csv\")\n",
    "cols = resp_full.columns[resp_full.columns.str.contains('GDSC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c6c61-31b3-460e-b137-c535039cfd6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def t_test(x, vadj=7.25): # 7.25 for 5x5 cv\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = len(x)\n",
    "    stat = np.mean(x) / np.sqrt(np.var(x)/n*vadj)\n",
    "    return 2 * stats.t.sf(np.abs(stat), n-1)\n",
    "\n",
    "\n",
    "def run_model_cv(X, y, outer_seed, inner_seed, model_dir, preds_dir, names, which_index, outer_folds = 5, inner_folds = 5, repeats = 5, baseline = False, save_models = False, model_type = \"eln\", check_for_trained = True, min_samples = 25):\n",
    "    \n",
    "    # predictions save path and check if its exists already\n",
    "    preds_filename = os.path.join(preds_dir, f\"predictions_{model_type}_{which_index}_{baseline}.csv\")\n",
    "    if check_for_trained:\n",
    "        if Path(preds_filename).exists():\n",
    "            print(\"emtpb: iteration \"+str(index)+\" already exists... skipping...\")\n",
    "            return\n",
    "    \n",
    "    # remove interesting variable for baseline\n",
    "    if baseline:\n",
    "        X = np.delete(X, 0, axis=1)\n",
    "    \n",
    "    # initialize list of all preds\n",
    "    all_all_predictions = []\n",
    "    all_all_truth = []\n",
    "    all_all_folds = []\n",
    "   \n",
    "    # Initialize names\n",
    "    names = pd.DataFrame(names)\n",
    "    names = pd.concat([names]*repeats, ignore_index = True)\n",
    "    \n",
    "    # check size of X,y and save placeholder\n",
    "    if mat.shape[0] < min_samples: # minimum 25 samples needed (5 test samples in outer cv and 4 in inner)\n",
    "        print(\"Amount of columns is only \"+str(mat.shape[0])+\"... skipping\")\n",
    "        names.to_csv(preds_filename, index=False)\n",
    "        return\n",
    "    \n",
    "    # initialize the outer cross-validation\n",
    "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=outer_seed)\n",
    "\n",
    "    # initialize the inner cross-validation\n",
    "    inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=inner_seed)\n",
    "\n",
    "    # repeat the outer cross-validation 5 times\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        # initialize the list to store the predictions\n",
    "        all_predictions = []\n",
    "        all_truth = []\n",
    "        all_folds = []\n",
    "\n",
    "        # set the seed for the outer cross-validation\n",
    "        outer_cv.random_state = outer_seed + repeat\n",
    "\n",
    "        # loop through the splits of the outer cross-validation\n",
    "        for i, (train_index, test_index) in enumerate(outer_cv.split(X)):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # initialize the model\n",
    "            if model_type == \"eln\":\n",
    "                model = ElasticNetCV(l1_ratio=[0.01, .1, .5, .9, .95, 1],\n",
    "                                     cv=inner_cv,\n",
    "                                     random_state=inner_seed,\n",
    "                                     tol=0.01\n",
    "                                    )\n",
    "            if model_type == \"rf\":\n",
    "                model = RandomForestRegressor(random_state=inner_seed)\n",
    "                \n",
    "            if model_type == \"mlp\":\n",
    "                model = MLPRegressor(max_iter=1000,\n",
    "                                     random_state=inner_seed)\n",
    "                # Define the hyperparameters to search over\n",
    "                \n",
    "                hidden_layer_sizes = [10, 50, 100, 150, 200]\n",
    "                n_layers = [2, 3 , 4]\n",
    "                layer_permutations = list(itertools.chain(*[itertools.permutations(hidden_layer_sizes, n) for n in n_layers]))\n",
    "                \n",
    "                param_grid = {\n",
    "                    'hidden_layer_sizes': layer_permutations\n",
    "                    #'activation': ['relu'] # 'identity', 'logistic', 'tanh', \n",
    "                    #'learning_rate_init': [0.001]\n",
    "                }\n",
    "                grid_search = RandomizedSearchCV(model, param_grid, cv=inner_folds, n_iter = 10, random_state = i+repeat*35)\n",
    "                grid_search.fit(X, y)\n",
    "                model = grid_search.best_estimator_\n",
    "                \n",
    "                # Get the best hyperparameters\n",
    "                print(grid_search.best_params_)\n",
    "\n",
    "            # fit the model on the training data\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # make predictions on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # save the predictions\n",
    "            all_predictions.append(y_pred)\n",
    "            all_truth.append(y_test)\n",
    "            all_folds.append([i]*len(y_test))\n",
    "\n",
    "            # save the model\n",
    "            model_filename = os.path.join(model_dir, f\"model_{model_type}_{which_index}_{baseline}_{repeat}_{i}.joblib\")\n",
    "            if save_models:\n",
    "                joblib.dump(model, model_filename)\n",
    "\n",
    "        # concatenate all the predictions from cv\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_truth = np.concatenate(all_truth)\n",
    "        all_folds = np.concatenate(all_folds)\n",
    "        \n",
    "        # save the cv results and append to resampling\n",
    "        all_all_predictions.append(all_predictions)\n",
    "        all_all_truth.append(all_truth)\n",
    "        all_all_folds.append(all_folds)\n",
    "    \n",
    "    # concatenate all the predictions\n",
    "    all_all_predictions = np.concatenate(all_all_predictions)\n",
    "    all_all_truth = np.concatenate(all_all_truth)\n",
    "    all_all_folds = np.concatenate(all_all_folds)\n",
    "    \n",
    "    names[\"preds\"] = all_all_predictions\n",
    "    names[\"truth\"] = all_all_truth#np.concatenate([y]*repeats)\n",
    "    names[\"repeat\"] = np.concatenate([[i]*len(y) for i in range(repeats)])\n",
    "    names[\"folds\"] = all_all_folds\n",
    "    names[\"repeatfold\"] = names[\"repeat\"].astype(str) + names[\"folds\"].astype(str)\n",
    "    \n",
    "    # save predictions \n",
    "    names.to_csv(preds_filename, index=False)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543c0d8-3677-427a-890a-ff452011bd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# benchmark\n",
    "for index in range(len(cols)):\n",
    "    \n",
    "    ### costum\n",
    "    #index = 0\n",
    "    ###\n",
    "    if not not example:\n",
    "        index = np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "    \n",
    "    print(\"emtpb: modelling iteration \"+str(index)+\"...\")\n",
    "    #index = np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "\n",
    "    # get one response column\n",
    "    resp = resp_full.copy()\n",
    "    resp = resp[[\"COSMIC ID\",\"TCGA Desc\",cols[index]]]\n",
    "    mat = pd.merge(EMTscores, resp, how='outer')\n",
    "    if cancertypes[which_run] != \"PANCAN\":\n",
    "        mat = mat[mat['TCGA Desc'] == cancertypes[which_run]]\n",
    "    mat = pd.merge(mat, mut, how='outer')\n",
    "    mat = pd.get_dummies(mat)\n",
    "    mat_df = mat\n",
    "    print(\"empb: shape before removing nan is \"+str(mat.shape))\n",
    "    mat.dropna(inplace=True)\n",
    "    print(\"empb: shape after removing nan is \"+str(mat.shape))\n",
    "    if mat.shape[0] == 0:\n",
    "        df = pd.DataFrame([[0]*mat.shape[1]],columns=mat.columns)\n",
    "        mat = mat.append(df, ignore_index=True)\n",
    "    names = mat['COSMIC ID']\n",
    "    mat.drop(columns=['COSMIC ID'], inplace=True)\n",
    "    response = mat.iloc[:,1] # mat.iloc[:,1] (drug response), # mat.iloc[:,0] (emt score)\n",
    "    mat = mat.drop(mat.columns[1], axis=1)\n",
    "    scale = StandardScaler()\n",
    "    mat = scale.fit_transform(mat)\n",
    "\n",
    "    for baseline in [True,False]: # [True, False]\n",
    "        df = run_model_cv(\n",
    "            X = mat,\n",
    "            y = np.array(response),\n",
    "            outer_seed = 53+53, \n",
    "            inner_seed = 53,\n",
    "            model_dir = model_dir,\n",
    "            preds_dir = preds_dir,\n",
    "            names = names,\n",
    "            which_index = index,\n",
    "            repeats = 5,\n",
    "            baseline = baseline,\n",
    "            model_type = model_type,\n",
    "            save_models = False,\n",
    "            check_for_trained = True,\n",
    "            outer_folds = 5\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        test = pd.read_csv(preds_dir+\"predictions_\"+str(model_type)+\"_\"+str(index)+\"_False.csv\")\n",
    "        perfalse = np.array(test.groupby(\"repeatfold\")[['preds','truth']].corr().iloc[1::2,0])\n",
    "        perfalse[np.isnan(perfalse)] = 0\n",
    "        print(perfalse)\n",
    "        print(np.mean(perfalse)) # \n",
    "        test = pd.read_csv(preds_dir+\"predictions_\"+str(model_type)+\"_\"+str(index)+\"_True.csv\")\n",
    "        pertrue = np.array(test.groupby(\"repeatfold\")[['preds','truth']].corr().iloc[1::2,0])\n",
    "        pertrue[np.isnan(pertrue)] = 0\n",
    "        print(pertrue)\n",
    "        print(np.mean(pertrue)) #\n",
    "        print(\"t-test p=\"+str(t_test(perfalse-pertrue)))\n",
    "        \n",
    "    if not not example:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43b280-6f49-459c-9c42-75ecb333ea62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"emt_pb: done modelling \"+cancertypes[which_run]+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f34bb-96f2-4322-ad59-294decb38008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.array(resp.iloc[:,2])\n",
    "#np.array(EMTscores.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b60d57-19f3-4373-9b0a-c849a9fa0023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check feature importances\n",
    "#m = joblib.load(\"metadata/run1/models/SKCM/model_513_False_0_0.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d68357-6a47-46f2-80d8-f240a58fc709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe4de5-e818-4bb1-87f8-11e2f3f32dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42231ee-5b3f-4b2a-a75f-f7408d363032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X = mat\n",
    "y = np.array(response)\n",
    "outer_seed = 53+53\n",
    "inner_seed = 53\n",
    "which_index = index\n",
    "repeats = 1\n",
    "baseline = True\n",
    "save_models = False\n",
    "check_for_trained = False\n",
    "outer_folds = 5\n",
    "inner_folds = 5\n",
    "min_samples = 5\n",
    "\n",
    "\n",
    "\n",
    "# predictions save path and check if its exists already\n",
    "### costum\n",
    "index = 0\n",
    "###\n",
    "if not not example:\n",
    "    index = np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "\n",
    "print(\"emtpb: modelling iteration \"+str(index)+\"...\")\n",
    "#index = np.where(cols == \"1559-GDSC2\")[0][0]\n",
    "\n",
    "# get one response column\n",
    "resp = resp_full.copy()\n",
    "resp = resp[[\"COSMIC ID\",\"TCGA Desc\",cols[index]]]\n",
    "mat = pd.merge(EMTscores, resp, how='outer')\n",
    "if cancertypes[which_run] != \"PANCAN\":\n",
    "    mat = mat[mat['TCGA Desc'] == cancertypes[which_run]]\n",
    "mat = pd.merge(mat, mut, how='outer')\n",
    "mat = pd.get_dummies(mat)\n",
    "mat_df = mat\n",
    "print(\"empb: shape before removing nan is \"+str(mat.shape))\n",
    "mat.dropna(inplace=True)\n",
    "print(\"empb: shape after removing nan is \"+str(mat.shape))\n",
    "if mat.shape[0] == 0:\n",
    "    df = pd.DataFrame([[0]*mat.shape[1]],columns=mat.columns)\n",
    "    mat = mat.append(df, ignore_index=True)\n",
    "names = mat['COSMIC ID']\n",
    "mat.drop(columns=['COSMIC ID'], inplace=True)\n",
    "response = mat.iloc[:,1] # mat.iloc[:,1] (drug response), # mat.iloc[:,0] (emt score)\n",
    "mat = mat.drop(mat.columns[1], axis=1)\n",
    "scale = StandardScaler()\n",
    "mat = scale.fit_transform(mat)\n",
    "\n",
    "\n",
    "preds_filename = os.path.join(preds_dir, f\"predictions_{model_type}_{which_index}_{baseline}.csv\")\n",
    "if check_for_trained:\n",
    "    if Path(preds_filename).exists():\n",
    "        print(\"emtpb: iteration \"+str(index)+\" already exists... skipping...\")\n",
    "\n",
    "# remove interesting variable for baseline\n",
    "if baseline:\n",
    "    X = np.delete(X, 0, axis=1)\n",
    "\n",
    "# initialize list of all preds\n",
    "all_all_predictions = []\n",
    "all_all_truth = []\n",
    "all_all_folds = []\n",
    "\n",
    "# Initialize names\n",
    "names = pd.DataFrame(names)\n",
    "names = pd.concat([names]*repeats, ignore_index = True)\n",
    "\n",
    "# check size of X,y and save placeholder\n",
    "if mat.shape[0] < min_samples: # minimum 25 samples needed (5 test samples in outer cv and 4 in inner)\n",
    "    print(\"Amount of columns is only \"+str(mat.shape[0])+\"... skipping\")\n",
    "    names.to_csv(preds_filename, index=False)\n",
    "\n",
    "# initialize the outer cross-validation\n",
    "outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=outer_seed)\n",
    "\n",
    "# initialize the inner cross-validation\n",
    "inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=inner_seed)\n",
    "\n",
    "\n",
    "    \n",
    "# repeat the outer cross-validation 5 times\n",
    "for repeat in range(repeats):\n",
    "\n",
    "    # initialize the list to store the predictions\n",
    "    all_predictions = []\n",
    "    all_truth = []\n",
    "    all_folds = []\n",
    "\n",
    "    # set the seed for the outer cross-validation\n",
    "    outer_cv.random_state = outer_seed + repeat\n",
    "\n",
    "    # loop through the splits of the outer cross-validation\n",
    "    for i, (train_index, test_index) in enumerate(outer_cv.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # initialize the model\n",
    "        if model_type == \"eln\":\n",
    "            model = ElasticNetCV(l1_ratio=[0.01, .1, .5, .9, .95, 1],\n",
    "                                 cv=inner_cv,\n",
    "                                 random_state=inner_seed,\n",
    "                                 tol=0.01\n",
    "                                )\n",
    "        if model_type == \"rf\":\n",
    "            model = RandomForestRegressor(random_state=inner_seed)\n",
    "\n",
    "        if model_type == \"mlp\":\n",
    "            model = MLPRegressor(max_iter=1000,\n",
    "                                 random_state=inner_seed)\n",
    "            # Define the hyperparameters to search over\n",
    "\n",
    "            hidden_layer_sizes = [10, 50, 100, 150, 200]\n",
    "            n_layers = [2, 3 , 4]\n",
    "            layer_permutations = list(itertools.chain(*[itertools.permutations(hidden_layer_sizes, n) for n in n_layers]))\n",
    "\n",
    "            param_grid = {\n",
    "                'hidden_layer_sizes': layer_permutations\n",
    "                #'activation': ['relu'] # 'identity', 'logistic', 'tanh', \n",
    "                #'learning_rate_init': [0.001]\n",
    "            }\n",
    "            grid_search = RandomizedSearchCV(model, param_grid, cv=inner_folds, n_iter = 10, random_state = i+repeat*35)\n",
    "            grid_search.fit(X, y)\n",
    "            model = grid_search.best_estimator_\n",
    "\n",
    "            # Get the best hyperparameters\n",
    "            print(grid_search.best_params_)\n",
    "\n",
    "        # fit the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # save the predictions\n",
    "        all_predictions.append(y_pred)\n",
    "        all_truth.append(y_test)\n",
    "        all_folds.append([i]*len(y_test))\n",
    "\n",
    "    # concatenate all the predictions from cv\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_truth = np.concatenate(all_truth)\n",
    "    all_folds = np.concatenate(all_folds)\n",
    "\n",
    "    # save the cv results and append to resampling\n",
    "    all_all_predictions.append(all_predictions)\n",
    "    all_all_truth.append(all_truth)\n",
    "    all_all_folds.append(all_folds)\n",
    "\n",
    "# concatenate all the predictions\n",
    "all_all_predictions = np.concatenate(all_all_predictions)\n",
    "all_all_truth = np.concatenate(all_all_truth)\n",
    "all_all_folds = np.concatenate(all_all_folds)\n",
    "\n",
    "print(all_all_predictions)\n",
    "print(all_all_truth)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fee49e-9caf-4568-9af8-ab17032231c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5904034-2e32-4f87-93b2-f8c48a9d9a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
